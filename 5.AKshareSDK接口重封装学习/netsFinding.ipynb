{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "# author: KarlQu\n",
    "# Version: 1.0\n",
    "# Date: 2022-09-28\n",
    "# requests.__version__ = '2.24.0'\n",
    "# webdriver.__version__ = '3.14.1'\n",
    "# pd.__version__ = '1.1.3'\n",
    "# ak.__version__ = '1.7.53 '\n",
    "# !最重要的是g和g的可达性\n",
    "# akshare更新非常频繁 1.7.53 \n",
    "# pip install akshare --upgrade -i https://pypi.org/simple\n",
    "\n",
    "# 是否需要更新10年pe均值和券商研报, pe_ave_10(ifupdate = False), 输出位置 f'./backups/{DATE}/nets_end.xlsx'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import akshare as ak\n",
    "import tqdm\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "import calendar\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "DATE = dt.date.today() # str(DATE) ; dt.date.today().year\n",
    "\n",
    "UA = {\n",
    "    'User-Agent':\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0'\n",
    "}\n",
    "\n",
    "def open_file(file_name:str, upperdir = 'backups'):\n",
    "    \"\"\"创建文件夹\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : 日期字符串\n",
    "    upperdir : 上级目录名\n",
    "    \"\"\"\n",
    "    if os.path.exists(f'./{upperdir}/' + file_name):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(f'./{upperdir}/' + file_name)\n",
    "\n",
    "def update_g(ifupdate = False) -> pd.DataFrame:\n",
    "    \"\"\"akshare的个股研报接口\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ifupdate : bool, optional\n",
    "        _description_, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        columns = ['代码','名称','研报数','2021预测每股收益','2022预测每股收益','2023预测每股收益','2024预测每股收益']\n",
    "    \"\"\"\n",
    "    if ifupdate:\n",
    "        open_file(str(DATE), upperdir = 'backups')\n",
    "        profit_forecast = ak.stock_profit_forecast().iloc[:,[1,2,3,9,10,11,12]].drop_duplicates()\n",
    "        profit_forecast.to_excel(f'./backups/{DATE}/profit_forecast.xlsx',index=False,encoding='utf-8')\n",
    "\n",
    "    else:\n",
    "        latest_file = list(os.walk('./backups/'))[0][1][-1]\n",
    "        profit_forecast = pd.read_excel(f'./backups/{latest_file}/profit_forecast.xlsx',dtype={'代码':'str'})\n",
    "    # 调整g,收益>0、每期g>10%、每期g可信值35%。 得到调整的几何均数g\n",
    "    profit_forecast = profit_forecast[(profit_forecast['2022预测每股收益']>0) & (profit_forecast['2023预测每股收益']>0 )& ( profit_forecast['2024预测每股收益']>0)]\n",
    "    profit_forecast1 = profit_forecast.iloc[:,[3,4,5,6]].pct_change(axis=1)[['2022预测每股收益','2023预测每股收益',\t'2024预测每股收益']]\n",
    "    profit_forecast2 = profit_forecast1[(profit_forecast1['2022预测每股收益']>0.1) & (profit_forecast1['2023预测每股收益']>0.1 )& ( profit_forecast1['2024预测每股收益']>0.1)]\n",
    "    profit_forecast2[profit_forecast2>0.35] = 0.35\n",
    "    profit_forecast3 = profit_forecast2 + 1\n",
    "    g_scaled = ((profit_forecast3['2022预测每股收益']*profit_forecast3['2023预测每股收益']*profit_forecast3['2024预测每股收益'])**(1/3)-1)\n",
    "    g_scaled.name = 'g'\n",
    "    g = pd.concat([g_scaled,profit_forecast],axis=1,join='inner')[['代码','名称','g','研报数']].reset_index(drop=True)\n",
    "    return g\n",
    "\n",
    "\n",
    "def ten_year_ago(date: dt.date = DATE) -> str:\n",
    "        \"\"\"10年前日期，月底对应月底\n",
    "        Parameters\n",
    "        ----------\n",
    "        date : datetime.date\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "        \"\"\"\n",
    "        year = date.year - 10\n",
    "        day = min(date.day, calendar.monthrange(year, date.month)[1])\n",
    "        dt = date.replace(year=year, month=date.month, day=day)\n",
    "        # print(dt)\n",
    "        bigen_date = str(dt).replace('-','')\n",
    "        return bigen_date\n",
    "\n",
    "def pe_ave_10(date:str = str(DATE), ifupdate = False):\n",
    "    \"\"\"获取or更新10年pe均值和券商研报的预期每股收益\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    date : str, optional\n",
    "        _description_, by default str(DATE)\n",
    "    ifupdate : bool, optional\n",
    "        _description_, by default False\n",
    "    \"\"\"\n",
    "    if ifupdate:\n",
    "        g = update_g(ifupdate=ifupdate)\n",
    "        stock_ids = g.代码.to_list() # 每次爬pe历史均值的时候都更新一下券商研报\n",
    "        # stock_ids = stock_ids[0:5]\n",
    "        # 1. selenium登录获取cookies\n",
    "        denglu_link = 'https://robo.datayes.com/v2/landing/peband'\n",
    "        cruser = webdriver.Firefox()\n",
    "        cruser.get(denglu_link)\n",
    "        input(\"扫码登录后按回车键\")\n",
    "        # WebDriverWait(cruser,60).until(EC.presence_of_all_elements_located((By.ID, 'app')))\n",
    "        cookies = {x['name']:x['value'] for x in cruser.get_cookies()}\n",
    "        # print(cookies)\n",
    "        end_date = date.replace('-','')\n",
    "        begin_date = ten_year_ago()\n",
    "        ave_pettm = []\n",
    "        for ids in tqdm.tqdm(stock_ids):\n",
    "            try:\n",
    "                url = f'https://gw.datayes.com/rrp_adventure/web/stockModel/band/{ids}'\n",
    "                response = requests.get(url=url,\n",
    "                                        params= {\n",
    "                                            'apiType': '4',\n",
    "                                            'category': '1',    # 1为PE，2为PB\n",
    "                                            'subCategory': '1',\n",
    "                                            'flag': '-1',\n",
    "                                            'beginDate': f'{begin_date}',\n",
    "                                            'endDate': f'{end_date}'\n",
    "                                        },\n",
    "                                        cookies=cookies,\n",
    "                                        headers=UA)\n",
    "                ave_pettm.append([ids, response.json()['data']['mean']])\n",
    "                time.sleep(np.random.rand()) # 1536/1536 [33:05<00:00,  1.29s/it]\n",
    "                # print(f'正常{response.status_code} , code: {ids}')\n",
    "            except:\n",
    "                print(f'异常{response.status_code} , code: {ids}')\n",
    "            continue\n",
    "        cruser.quit()\n",
    "        # 3. 本地保存\n",
    "        pe_ave = pd.DataFrame(ave_pettm, columns=['code','ave_pettm'])\n",
    "        open_file(str(DATE), upperdir = 'backups')\n",
    "        pe_ave.to_excel(f'./backups/{DATE}/avepettm_backup.xlsx',encoding='utf-8',index=False)\n",
    "    else:\n",
    "        latest_file = list(os.walk('./backups/'))[0][1][-1]\n",
    "        g = update_g(ifupdate=ifupdate)\n",
    "        pe_ave = pd.read_excel(f'./backups/{latest_file}/avepettm_backup.xlsx',dtype={'code':'str'})\n",
    "    nets = pd.merge(g.rename(columns={'代码':'code'}) , pe_ave , on='code',how='left')\n",
    "    nets['peg'] = (nets.ave_pettm / (100*nets.g))\n",
    "    nets1 = nets[(nets['peg']<1.2)]\n",
    "    # (nets['peg']<1.2).sum()\n",
    "    # 2. 得到筛选后的股票代码，后续可以爬取pettm和dvttm了\n",
    "    stock_ids_selected = nets1.code.to_list() \n",
    "    pe_ttm = []\n",
    "    for ids in tqdm.tqdm(stock_ids_selected):\n",
    "        try:\n",
    "            rrr = ak.stock_a_lg_indicator(symbol=f'{ids}').iloc[-1,[0,2,7]] # pettm and dvttm 接口\n",
    "            rrr['industry'] = ak.stock_individual_info_em(symbol=f\"{ids}\").loc[2].value # 行业接口\n",
    "            rrr.name = ids\n",
    "            pe_ttm.append(rrr)\n",
    "        except:\n",
    "            print(f'{ids} 查无!')\n",
    "        continue\n",
    "    pe_and_dv = pd.concat(pe_ttm,axis=1).T\n",
    "    pe_and_dv_backup = pe_and_dv.reset_index(drop=False)\n",
    "    pe_and_dv_backup = pe_and_dv_backup.rename(columns={'index':'code'}) \n",
    "    open_file(str(DATE), upperdir = 'backups')\n",
    "    pe_and_dv_backup.to_excel(f'./backups/{DATE}/pe_and_dv.xlsx',index=False,encoding='utf-8')\n",
    "    # pe_ttm = pd.read_excel(f'./backups/{DATE}/pe_and_dv.xlsx',dtype={'code':'str'})\n",
    "    nets2 = pd.merge(nets1,pe_and_dv_backup,on='code',how='left')\n",
    "    nets3 = nets2[nets2.pe_ttm<nets2.ave_pettm]\n",
    "    nets3['peg'] = (nets3.pe_ttm / (100*nets3.g))\n",
    "    nets3['exp_reward_yearly'] = 100*((nets3.ave_pettm/nets3.pe_ttm)**(1/3)*(1+nets3.g)-1)\n",
    "    nets_end = nets3[nets3.exp_reward_yearly>35].drop_duplicates()\n",
    "    nets_end.to_excel(f'./backups/{DATE}/nets_end.xlsx',index=False,encoding='utf-8')        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-c842f31e5746>:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  profit_forecast2[profit_forecast2>0.35] = 0.35\n",
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3215: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._where(-key, value, inplace=True)\n",
      "100%|██████████| 347/347 [06:04<00:00,  1.05s/it]\n",
      "<ipython-input-17-c842f31e5746>:177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nets3['peg'] = (nets3.pe_ttm / (100*nets3.g))\n",
      "<ipython-input-17-c842f31e5746>:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nets3['exp_reward_yearly'] = 100*((nets3.ave_pettm/nets3.pe_ttm)**(1/3)*(1+nets3.g)-1)\n"
     ]
    }
   ],
   "source": [
    "pe_ave_10(ifupdate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
