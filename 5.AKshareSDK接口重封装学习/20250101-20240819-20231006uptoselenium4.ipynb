{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 2023年10月6日开始重构\n",
    "\n",
    "- 1.akshare有一个接口更新了名字\n",
    "- 2.券商研报的表头更新了\n",
    "- 3.通过萝卜投研爬取10年pe平均值做了线程池优化（12个workers让本来50分钟的爬取减少到5分钟）\n",
    "\n",
    "# 2024年7月3日更新券商研报的表头，其他都没变化\n",
    "# 2024年8月19日更新akshare=1.14.62 接口行业的表头\n",
    "\n",
    "# 2025年1月1日重构 因legulegu.com的接口对爬虫效率进行了封禁，封半小时。 因此随机化sleep，可以爬了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f176c73bbb245ba992e6ec402331c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>序号</th>\n",
       "      <th>代码</th>\n",
       "      <th>名称</th>\n",
       "      <th>研报数</th>\n",
       "      <th>机构投资评级(近六个月)-买入</th>\n",
       "      <th>机构投资评级(近六个月)-增持</th>\n",
       "      <th>机构投资评级(近六个月)-中性</th>\n",
       "      <th>机构投资评级(近六个月)-减持</th>\n",
       "      <th>机构投资评级(近六个月)-卖出</th>\n",
       "      <th>2023预测每股收益</th>\n",
       "      <th>2024预测每股收益</th>\n",
       "      <th>2025预测每股收益</th>\n",
       "      <th>2026预测每股收益</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>600519</td>\n",
       "      <td>贵州茅台</td>\n",
       "      <td>54</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.492280</td>\n",
       "      <td>68.552926</td>\n",
       "      <td>76.680037</td>\n",
       "      <td>85.386075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>000858</td>\n",
       "      <td>五粮液</td>\n",
       "      <td>50</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.783008</td>\n",
       "      <td>8.487680</td>\n",
       "      <td>9.232860</td>\n",
       "      <td>10.125469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>603605</td>\n",
       "      <td>珀莱雅</td>\n",
       "      <td>49</td>\n",
       "      <td>37.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.012935</td>\n",
       "      <td>3.876612</td>\n",
       "      <td>4.800878</td>\n",
       "      <td>5.798563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>300750</td>\n",
       "      <td>宁德时代</td>\n",
       "      <td>47</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.019663</td>\n",
       "      <td>11.665891</td>\n",
       "      <td>14.195370</td>\n",
       "      <td>16.803422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>600809</td>\n",
       "      <td>山西汾酒</td>\n",
       "      <td>47</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.556082</td>\n",
       "      <td>10.244915</td>\n",
       "      <td>11.825532</td>\n",
       "      <td>13.615152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   序号      代码    名称  研报数  机构投资评级(近六个月)-买入  机构投资评级(近六个月)-增持  机构投资评级(近六个月)-中性  \\\n",
       "0   1  600519  贵州茅台   54             47.0              7.0              0.0   \n",
       "1   2  000858   五粮液   50             40.0             10.0              0.0   \n",
       "2   3  603605   珀莱雅   49             37.0             12.0              0.0   \n",
       "3   4  300750  宁德时代   47             36.0             11.0              0.0   \n",
       "4   5  600809  山西汾酒   47             38.0              9.0              0.0   \n",
       "\n",
       "   机构投资评级(近六个月)-减持  机构投资评级(近六个月)-卖出  2023预测每股收益  2024预测每股收益  2025预测每股收益  \\\n",
       "0              0.0              0.0   59.492280   68.552926   76.680037   \n",
       "1              0.0              0.0    7.783008    8.487680    9.232860   \n",
       "2              0.0              0.0    3.012935    3.876612    4.800878   \n",
       "3              0.0              0.0   10.019663   11.665891   14.195370   \n",
       "4              0.0              0.0    8.556082   10.244915   11.825532   \n",
       "\n",
       "   2026预测每股收益  \n",
       "0   85.386075  \n",
       "1   10.125469  \n",
       "2    5.798563  \n",
       "3   16.803422  \n",
       "4   13.615152  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import akshare as ak\n",
    "# (base) [1,2,3,9,10,11,12]\n",
    "ak.stock_profit_forecast_em().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python=3.10\n",
    "# coding=utf-8\n",
    "# author: KarlQu\n",
    "# Version: 1.3\n",
    "# Date: 2025-01-01\n",
    "# webdriver=Firefox2023.04\n",
    "# pip install akshare -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com  --upgrade\n",
    "#  mamba install -c conda-forge selenium=4.13.0\n",
    "# selenium 4 与 selenium 3 对对象选择语法做了修改\n",
    "#  mamba install -c conda-forge jupyter\n",
    "# akshare.__version__ = '1.14.62 '\n",
    "# !最重要的是g和g的可达性\n",
    "# akshare更新非常频繁\n",
    "# pip install akshare --upgrade -i https://pypi.org/simple\n",
    "\n",
    "# 是否需要更新10年pe均值和券商研报, pe_ave_10(ifupdate = False), 输出位置 f'./backups/{DATE}/nets_end.xlsx'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import akshare as ak\n",
    "import tqdm\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "import calendar\n",
    "from selenium import webdriver\n",
    "# from selenium.webdriver.support.wait import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver.common.by import By\n",
    "from concurrent import futures\n",
    "\n",
    "DATE = dt.date.today() # str(DATE) ; dt.date.today().year\n",
    "\n",
    "UA = {\n",
    "    'User-Agent':\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0'\n",
    "}\n",
    "\n",
    "def open_file(file_name:str, upperdir = 'backups'):\n",
    "    \"\"\"创建文件夹\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : 日期字符串\n",
    "    upperdir : 上级目录名\n",
    "    \"\"\"\n",
    "    if os.path.exists(f'./{upperdir}/' + file_name):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(f'./{upperdir}/' + file_name)\n",
    "\n",
    "def update_g(ifupdate = False) -> pd.DataFrame:\n",
    "    \"\"\"akshare的个股研报接口\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ifupdate : bool, optional\n",
    "        _description_, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        columns = ['代码','名称','研报数','2021预测每股收益','2022预测每股收益','2023预测每股收益','2024预测每股收益']\n",
    "        \n",
    "        共4年的每股收益,2023年更新为'2022预测每股收益','2023预测每股收益','2024预测每股收益','2025预测每股收益'\n",
    "\n",
    "    \"\"\"\n",
    "    if ifupdate:\n",
    "        open_file(str(DATE), upperdir = 'backups')\n",
    "        profit_forecast = ak.stock_profit_forecast_em().iloc[:,[1,2,3,9,10,11,12]].drop_duplicates()\n",
    "        profit_forecast.to_excel(f'./backups/{DATE}/profit_forecast.xlsx',index=False)\n",
    "\n",
    "    else:\n",
    "        latest_file = list(os.walk('./backups/'))[0][1][-1]\n",
    "        profit_forecast = pd.read_excel(f'./backups/{latest_file}/profit_forecast.xlsx',dtype={'代码':'str'})\n",
    "    # 调整g,收益>0、每期g>10%、每期g可信值35%。 得到调整的几何均数g\n",
    "    profit_forecast = profit_forecast[(profit_forecast['2023预测每股收益']>0) & (profit_forecast['2024预测每股收益']>0 )& ( profit_forecast['2025预测每股收益']>0)]\n",
    "    profit_forecast\n",
    "    profit_forecast1 = profit_forecast.iloc[:,[3,4,5,6]].pct_change(axis=1)[['2024预测每股收益','2025预测每股收益',\t'2026预测每股收益']]\n",
    "    profit_forecast1\n",
    "    profit_forecast2 = profit_forecast1[(profit_forecast1['2024预测每股收益']>0.1) & (profit_forecast1['2025预测每股收益']>0.1 )& ( profit_forecast1['2026预测每股收益']>0.1)]\n",
    "    profit_forecast2\n",
    "    profit_forecast2[profit_forecast2>0.35] = 0.35\n",
    "    profit_forecast3 = profit_forecast2 + 1\n",
    "    g_scaled = ((profit_forecast3['2024预测每股收益']*profit_forecast3['2025预测每股收益']*profit_forecast3['2026预测每股收益'])**(1/3)-1)\n",
    "    g_scaled.name = 'g'\n",
    "    g = pd.concat([g_scaled,profit_forecast],axis=1,join='inner')[['代码','名称','g','研报数']].reset_index(drop=True)\n",
    "    return g\n",
    "\n",
    "\n",
    "def ten_year_ago(date: dt.date = DATE) -> str:\n",
    "        \"\"\"10年前日期，月底对应月底\n",
    "        Parameters\n",
    "        ----------\n",
    "        date : datetime.date\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "        \"\"\"\n",
    "        year = date.year - 10\n",
    "        day = min(date.day, calendar.monthrange(year, date.month)[1])\n",
    "        dt = date.replace(year=year, month=date.month, day=day)\n",
    "        # print(dt)\n",
    "        bigen_date = str(dt).replace('-','')\n",
    "        return bigen_date\n",
    "\n",
    "# 是否需要更新10年pe均值和券商研报, 默认pe_ave_10(ifupdate = False), \n",
    "# 输出位置 f'./backups/{DATE}/nets_end.xlsx'\n",
    "def pe_ave_10(date:str = str(DATE), ifupdate = False):\n",
    "    \"\"\"获取or更新10年pe均值和券商研报的预期每股收益\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    date : str, optional\n",
    "        _description_, by default str(DATE)\n",
    "    ifupdate : bool, optional\n",
    "        _description_, by default False\n",
    "    \"\"\"\n",
    "    if ifupdate:\n",
    "        g = update_g(ifupdate=ifupdate)\n",
    "        stock_ids = g.代码.to_list() # 每次爬pe历史均值的时候都更新一下券商研报\n",
    "        print('代码前五个')\n",
    "        print(stock_ids[0:5])\n",
    "        print('-----------------开始爬取萝卜pe历史均值---------------')\n",
    "        # 1. selenium登录获取cookies\n",
    "        denglu_link = 'https://robo.datayes.com/v2/landing/peband'\n",
    "        cruser = webdriver.Firefox()\n",
    "        cruser.get(denglu_link)\n",
    "        input(\"扫码登录后按回车键\")\n",
    "        # WebDriverWait(cruser,60).until(EC.presence_of_all_elements_located((By.ID, 'app')))\n",
    "        cookies = {x['name']:x['value'] for x in cruser.get_cookies()}\n",
    "        print(cookies)\n",
    "        end_date = date.replace('-','')\n",
    "        begin_date = ten_year_ago()\n",
    "        ave_pettm = []\n",
    "        executor = futures.ThreadPoolExecutor(max_workers=12)\n",
    "        fs = []\n",
    "        total_tasks = len(stock_ids)\n",
    "        with tqdm.tqdm(total=total_tasks) as pbar:\n",
    "            for ids in stock_ids:\n",
    "                def get_ids_peave(ids, begin_date, end_date, cookies, UA, ave_pettm):\n",
    "                    try:\n",
    "                        url = f'https://gw.datayes.com/rrp_adventure/web/stockModel/band/{ids}' # 2022old\n",
    "                        response = requests.get(url=url,\n",
    "                                                params= {\n",
    "                                                    'apiType': '4',\n",
    "                                                    'category': '1',    # 1为PE，2为PB\n",
    "                                                    'subCategory': '1',\n",
    "                                                    'flag': '-1',\n",
    "                                                    'beginDate': f'{begin_date}',\n",
    "                                                    'endDate': f'{end_date}'\n",
    "                                                },\n",
    "                                                cookies=cookies,\n",
    "                                                headers=UA)\n",
    "                        ave_pettm.append([ids, response.json()['data']['mean']])\n",
    "                        pbar.update(1) # 更新tqdm进度条用\n",
    "                        time.sleep(np.random.rand()) # 1536/1536 [33:05<00:00,  1.29s/it]\n",
    "                        # print(f'正常{response.status_code} , code: {ids}')\n",
    "                    except:\n",
    "                        print(f'异常{response.status_code} , code: {ids}')\n",
    "                        pass\n",
    "\n",
    "                f= executor.submit(get_ids_peave, ids, begin_date, end_date, cookies, UA, ave_pettm)\n",
    "                fs.append(f)\n",
    "            futures.wait(fs)\n",
    "        cruser.quit()\n",
    "        # 3. 本地保存\n",
    "        pe_ave = pd.DataFrame(ave_pettm, columns=['code','ave_pettm'])\n",
    "        open_file(str(DATE), upperdir = 'backups')\n",
    "        pe_ave.to_excel(f'./backups/{DATE}/avepettm_backup.xlsx',index=False)\n",
    "        latest_file = DATE\n",
    "    else:\n",
    "        latest_file = list(os.walk('./backups/'))[0][1][-1]\n",
    "        print(f'研报和10年期pe平均值的最近一次更新时间为 {latest_file}')\n",
    "        g = update_g(ifupdate=ifupdate)\n",
    "        pe_ave = pd.read_excel(f'./backups/{latest_file}/avepettm_backup.xlsx',dtype={'code':'str'})\n",
    "    nets = pd.merge(g.rename(columns={'代码':'code'}) , pe_ave , on='code',how='left')\n",
    "    nets['peg'] = (nets.ave_pettm / (100*nets.g))\n",
    "    nets1 = nets[(nets['peg']<1.2)]\n",
    "    # (nets['peg']<1.2).sum()\n",
    "    # 2. 得到筛选后的股票代码，后续可以爬取pettm和dvttm了\n",
    "    stock_ids_selected = nets1.code.to_list()\n",
    "    print('DEBUG:print 代码前五')\n",
    "    print(stock_ids_selected[0:5])\n",
    "    pe_ttm = []\n",
    "    for ids in tqdm.tqdm(stock_ids_selected):\n",
    "\n",
    "        try:\n",
    "            rrr = ak.stock_a_indicator_lg(symbol=f'{ids}').iloc[-1,[0,2,7]] # pettm and dvttm 接口\n",
    "            # print(f\"rrr {rrr}\")\n",
    "            rrr['industry'] = ak.stock_individual_info_em(symbol=f\"{ids}\").loc[6].value # 行业接口\n",
    "            # print(f\"rrr with industry {rrr}\")\n",
    "            rrr.name = ids\n",
    "            pe_ttm.append(rrr)\n",
    "\n",
    "            time.sleep(1 + np.random.rand()) # 反扒试试。。\n",
    "            \n",
    "        except:\n",
    "            print(f'{ids} 查无!')\n",
    "        continue\n",
    "\n",
    "    pe_and_dv = pd.concat(pe_ttm,axis=1).T\n",
    "    pe_and_dv_backup = pe_and_dv.reset_index(drop=False)\n",
    "    pe_and_dv_backup = pe_and_dv_backup.rename(columns={'index':'code'}) \n",
    "    open_file(str(DATE), upperdir = f'backups/{latest_file}')\n",
    "    pe_and_dv_backup.to_excel(f'./backups/{latest_file}/{DATE}/pe_and_dv.xlsx',index=False)\n",
    "    # pe_ttm = pd.read_excel(f'./backups/{latest_file}/{DATE}/pe_and_dv.xlsx',dtype={'code':'str'})\n",
    "    nets2 = pd.merge(nets1,pe_and_dv_backup,on='code',how='left')\n",
    "    nets3 = nets2[nets2.pe_ttm<nets2.ave_pettm]\n",
    "    nets3['peg'] = (nets3.pe_ttm / (100*nets3.g))\n",
    "    nets3['exp_reward_yearly'] = 100*((nets3.ave_pettm/nets3.pe_ttm)**(1/3)*(1+nets3.g)-1)\n",
    "    nets_end = nets3[nets3.exp_reward_yearly>35].drop_duplicates()\n",
    "    nets_end.to_excel(f'./backups/{latest_file}/{DATE}/nets_end.xlsx',index=False)   \n",
    "    print('done! open nets_end.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 行业接口的表头由[2]到[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'酿酒行业'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.stock_individual_info_em(symbol=f\"603198\").loc[6].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trade_date    2024-12-31\n",
       "pe_ttm           16.3509\n",
       "dv_ttm            2.4101\n",
       "Name: 2334, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网站对爬虫速度进行了限制\n",
    "ak.stock_a_indicator_lg(symbol=f'603198').iloc[-1,[0,2,7]] # pettm and dvttm 接口\n",
    "\n",
    "\n",
    "# 如果上面不行试试更新akshare版本\n",
    "# !pip install akshare --upgrade -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     trade_date       pe   pe_ttm      pb      ps  ps_ttm dv_ratio  dv_ttm  \\\n",
      "0      20241231  12.2998  11.2867  1.5371  0.8998  0.8858   1.8833  3.0122   \n",
      "1      20241230  12.7179  11.6704  1.5893  0.9304  0.9159   1.8214  2.9132   \n",
      "2      20241227  12.6761   11.632  1.5841  0.9274  0.9129   1.8274  2.9228   \n",
      "3      20241226  12.7598  11.7088  1.5946  0.9335  0.9189   1.8154  2.9036   \n",
      "4      20241225  12.5786  11.5425  1.5719  0.9202  0.9059   1.8416  2.9454   \n",
      "...         ...      ...      ...     ...     ...     ...      ...     ...   \n",
      "5595   20010928  33.0156  25.8967  2.8183  3.9697  3.6028      0.0  6.9242   \n",
      "5596   20010927  32.4191  25.4289  2.7674   3.898  3.5377      0.0  7.0516   \n",
      "5597   20010926  32.3139  25.3463  2.7584  3.8854  3.5262      0.0  7.0746   \n",
      "5598   20010925  31.7174  24.8785  2.7075  3.8136  3.4611      0.0  7.2076   \n",
      "5599   20010924  30.9455   24.273  2.6416  3.7208  3.3769      0.0  7.3874   \n",
      "\n",
      "          total_mv  \n",
      "0     1572072.7232  \n",
      "1     1625514.2888  \n",
      "2     1620170.1323  \n",
      "3     1630858.4454  \n",
      "4     1607700.4336  \n",
      "...            ...  \n",
      "5595   192562.7687  \n",
      "5596   189083.9514  \n",
      "5597   188470.0424  \n",
      "5598   184991.2251  \n",
      "5599   180489.2263  \n",
      "\n",
      "[5600 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# 从akshare里截取的实现\n",
    "\n",
    "from datetime import datetime\n",
    "from hashlib import md5\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from akshare.utils.cons import headers\n",
    "\n",
    "def get_cookie_csrf(url: str = \"\") -> dict:\n",
    "    \"\"\"\n",
    "    乐咕乐股-主板市盈率\n",
    "    https://legulegu.com/stockdata/shanghaiPE\n",
    "    :return: 指定市场的市盈率数据\n",
    "    :rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, features=\"lxml\")\n",
    "    csrf_tag = soup.find(name=\"meta\", attrs={\"name\": \"_csrf\"})\n",
    "    csrf_token = csrf_tag.attrs[\"content\"]\n",
    "    headers.update({\"X-CSRF-Token\": csrf_token})\n",
    "    return {\"cookies\": r.cookies, \"headers\": headers}\n",
    "\n",
    "\n",
    "def get_token_lg() -> str:\n",
    "    \"\"\"\n",
    "    生成乐咕的 token\n",
    "    https://legulegu.com/s/002488\n",
    "    :return: token\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    current_date_str = datetime.now().date().isoformat()\n",
    "    obj = md5()\n",
    "    obj.update(current_date_str.encode(\"utf-8\"))\n",
    "    token = obj.hexdigest()\n",
    "    return token\n",
    "\n",
    "symbol = \"600761\"\n",
    "url = \"https://legulegu.com/api/s/base-info/\"\n",
    "token = get_token_lg()\n",
    "params = {\"token\": token, \"id\": symbol}\n",
    "r = requests.post(\n",
    "    url,\n",
    "    params=params,\n",
    "    **get_cookie_csrf(url=\"https://legulegu.com/\"),\n",
    ")\n",
    "temp_json = r.json()\n",
    "temp_df = pd.DataFrame(\n",
    "    temp_json[\"data\"][\"items\"],\n",
    "    columns=temp_json[\"data\"][\"fields\"],\n",
    ")\n",
    "print(temp_df)\n",
    "temp_df[\"trade_date\"] = pd.to_datetime(temp_df[\"trade_date\"]).dt.date\n",
    "temp_df[temp_df.columns[1:]] = temp_df[temp_df.columns[1:]].astype(float)\n",
    "temp_df.sort_values(by=[\"trade_date\"], inplace=True, ignore_index=True)\n",
    "if len(set(temp_df[\"trade_date\"])) <= 0:\n",
    "    raise ValueError(\"数据获取失败, 请检查是否输入正确的股票代码\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "研报和10年期pe平均值的最近一次更新时间为 2025-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14988\\2610632021.py:79: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  profit_forecast1 = profit_forecast.iloc[:,[3,4,5,6]].pct_change(axis=1)[['2024预测每股收益','2025预测每股收益',\t'2026预测每股收益']]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14988\\2610632021.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  profit_forecast2[profit_forecast2>0.35] = 0.35\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14988\\2610632021.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  profit_forecast2[profit_forecast2>0.35] = 0.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:print 代码前五\n",
      "['600761', '603193', '002648', '600426', '003006']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [08:45<00:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done! open nets_end.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14988\\2610632021.py:210: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nets3['peg'] = (nets3.pe_ttm / (100*nets3.g))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14988\\2610632021.py:211: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nets3['exp_reward_yearly'] = 100*((nets3.ave_pettm/nets3.pe_ttm)**(1/3)*(1+nets3.g)-1)\n"
     ]
    }
   ],
   "source": [
    "# 真正的运行吧！\n",
    "\n",
    "# pe_ave_10(ifupdate=True)\n",
    "pe_ave_10(ifupdate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 后记\n",
    "## 1.使用结果net_end.xlsx来选股\n",
    "> tips:2022-10-14选的股，到现在(2024.7.3)看都有了35%的收益\n",
    "\n",
    "**net_end.xlsx**\n",
    "\n",
    "- 1 首先用peg和pe_ttm做降序排序\n",
    "- 2 看pe_ttm与10年平均pe的距离\n",
    "- 3 优先选dv_ttm（股息率）高于3.4的\n",
    "- 4 对比g（券商研报）,看能不能支撑pe_ttm的回报率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.pip install -r requirements.txt:\n",
    "\n",
    "\n",
    "> akshare==1.15.61\n",
    "anyio @ file:///C:/b/abs_847uobe7ea/croot/anyio_1706220224037/work\n",
    "argon2-cffi @ file:///opt/conda/conda-bld/argon2-cffi_1645000214183/work\n",
    "argon2-cffi-bindings @ file:///C:/ci/argon2-cffi-bindings_1644569876605/work\n",
    "asttokens @ file:///opt/conda/conda-bld/asttokens_1646925590279/work\n",
    "async-lru @ file:///C:/b/abs_e0hjkvwwb5/croot/async-lru_1699554572212/work\n",
    "attrs @ file:///C:/b/abs_35n0jusce8/croot/attrs_1695717880170/work\n",
    "Babel @ file:///C:/b/abs_a2shv_3tqi/croot/babel_1671782804377/work\n",
    "backcall==0.2.0\n",
    "beautifulsoup4 @ file:///C:/b/abs_d5wytg_p0w/croot/beautifulsoup4-split_1718029833749/work\n",
    "bleach @ file:///opt/conda/conda-bld/bleach_1641577558959/work\n",
    "Brotli @ file:///C:/b/abs_3d36mno480/croot/brotli-split_1714483178642/work\n",
    "certifi @ file:///C:/b/abs_1fw_exq1si/croot/certifi_1725551736618/work/certifi\n",
    "cffi @ file:///C:/b/abs_78eb1_vq6z/croot/cffi_1714483206096/work\n",
    "charset-normalizer @ file:///croot/charset-normalizer_1721748349566/work\n",
    "colorama @ file:///C:/b/abs_a9ozq0l032/croot/colorama_1672387194846/work\n",
    "comm @ file:///C:/b/abs_67a8058udb/croot/comm_1709322909844/work\n",
    "contourpy @ file:///D:/bld/contourpy_1725378323525/work\n",
    "cycler @ file:///tmp/build/80754af9/cycler_1637851556182/work\n",
    "debugpy @ file:///C:/b/abs_c0y1fjipt2/croot/debugpy_1690906864587/work\n",
    "decorator @ file:///opt/conda/conda-bld/decorator_1643638310831/work\n",
    "defusedxml @ file:///tmp/build/80754af9/defusedxml_1615228127516/work\n",
    "docopt==0.6.2\n",
    "et-xmlfile==1.1.0\n",
    "exceptiongroup @ file:///C:/b/abs_c5h1o1_b5b/croot/exceptiongroup_1706031441653/work\n",
    "executing @ file:///opt/conda/conda-bld/executing_1646925071911/work\n",
    "fastjsonschema @ file:///C:/Users/BUILDE~1/AppData/Local/Temp/abs_ebruxzvd08/croots/recipe/python-fastjsonschema_1661376484940/work\n",
    "fonttools @ file:///C:/b/abs_f47gnfqnx0/croot/fonttools_1713551644747/work\n",
    "h11 @ file:///C:/b/abs_1czwoyexjf/croot/h11_1706652332846/work\n",
    "html5lib==1.1\n",
    "idna @ file:///C:/b/abs_aad84bnnw5/croot/idna_1714398896795/work\n",
    "ipykernel @ file:///C:/b/abs_c2u94kxcy6/croot/ipykernel_1705933907920/work\n",
    "ipython==8.12.3\n",
    "ipywidgets @ file:///C:/b/abs_25rsd7yhd4/croot/ipywidgets_1709575117021/work\n",
    "jedi @ file:///C:/b/abs_1b8kmj7rrm/croot/jedi_1721058359741/work\n",
    "Jinja2 @ file:///C:/b/abs_92fccttino/croot/jinja2_1716993447201/work\n",
    "json5 @ file:///tmp/build/80754af9/json5_1624432770122/work\n",
    "jsonpath==0.82.2\n",
    "jsonschema @ file:///C:/b/abs_d1c4sm8drk/croot/jsonschema_1699041668863/work\n",
    "jsonschema-specifications @ file:///C:/b/abs_0brvm6vryw/croot/jsonschema-specifications_1699032417323/work\n",
    "jupyter @ file:///C:/b/abs_4e102rc6e5/croot/jupyter_1707947170513/work\n",
    "jupyter-console @ file:///C:/b/abs_82xaa6i2y4/croot/jupyter_console_1680000189372/work\n",
    "jupyter-events @ file:///C:/b/abs_c2m9s5b5m5/croot/jupyter_events_1718738115254/work\n",
    "jupyter-lsp @ file:///C:/b/abs_ecle3em9d4/croot/jupyter-lsp-meta_1699978291372/work\n",
    "jupyter_client @ file:///C:/b/abs_a6h3c8hfdq/croot/jupyter_client_1699455939372/work\n",
    "jupyter_core @ file:///C:/b/abs_beftpbuevw/croot/jupyter_core_1718818307097/work\n",
    "jupyter_server @ file:///C:/b/abs_9a333nh6yu/croot/jupyter_server_1718827092223/work\n",
    "jupyter_server_terminals @ file:///C:/b/abs_ec0dq4b50j/croot/jupyter_server_terminals_1686870763512/work\n",
    "jupyterlab @ file:///C:/b/abs_43venm28fu/croot/jupyterlab_1706802651134/work\n",
    "jupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work\n",
    "jupyterlab-widgets @ file:///C:/b/abs_62picw9xos/croot/jupyterlab_widgets_1709323131962/work\n",
    "jupyterlab_server @ file:///C:/b/abs_e08i7qn9m8/croot/jupyterlab_server_1699555481806/work\n",
    "kiwisolver @ file:///C:/b/abs_88mdhvtahm/croot/kiwisolver_1672387921783/work\n",
    "lxml==5.3.0\n",
    "MarkupSafe @ file:///C:/b/abs_ecfdqh67b_/croot/markupsafe_1704206030535/work\n",
    "matplotlib==3.9.2\n",
    "matplotlib-inline @ file:///C:/ci/matplotlib-inline_1661934094726/work\n",
    "mini-racer==0.12.4\n",
    "mistune @ file:///C:/Users/BUILDE~1/AppData/Local/Temp/abs_081kimkskf/croots/recipe/mistune_1661496225923/work\n",
    "mkl-service==2.4.0\n",
    "mkl_fft @ file:///C:/b/abs_f55mv94vyg/croot/mkl_fft_1725370278455/work\n",
    "mkl_random @ file:///C:/b/abs_21ydbzdu8d/croot/mkl_random_1725370276095/work\n",
    "nbclient @ file:///C:/b/abs_cal0q5fyju/croot/nbclient_1698934263135/work\n",
    "nbconvert==7.16.4\n",
    "nbformat @ file:///C:/b/abs_5a2nea1iu2/croot/nbformat_1694616866197/work\n",
    "nest-asyncio @ file:///C:/b/abs_65d6lblmoi/croot/nest-asyncio_1708532721305/work\n",
    "notebook @ file:///C:/b/abs_09nvambyty/croot/notebook_1719499424678/work\n",
    "notebook_shim @ file:///C:/b/abs_a5xysln3lb/croot/notebook-shim_1699455926920/work\n",
    "numpy @ file:///C:/b/abs_0123vcxhf8/croot/numpy_and_numpy_base_1725470331966/work/dist/numpy-2.0.1-cp310-cp310-win_amd64.whl#sha256=e824ec3b279f4c5207736c83ac2f2dc79b489e08501a4ea9e3fc178c45db289b\n",
    "openpyxl @ file:///C:/b/abs_0e6ca21lac/croot/openpyxl_1721752965859/work\n",
    "outcome @ file:///tmp/build/80754af9/outcome_1609338780791/work\n",
    "overrides @ file:///C:/b/abs_cfh89c8yf4/croot/overrides_1699371165349/work\n",
    "packaging @ file:///C:/b/abs_c3vlh0z4jw/croot/packaging_1720101866539/work\n",
    "pandas @ file:///D:/bld/pandas_1715897730709/work\n",
    "pandocfilters @ file:///opt/conda/conda-bld/pandocfilters_1643405455980/work\n",
    "parso @ file:///opt/conda/conda-bld/parso_1641458642106/work\n",
    "patsy @ file:///home/conda/feedstock_root/build_artifacts/patsy_1704469236901/work\n",
    "pickleshare==0.7.5\n",
    "pillow @ file:///C:/b/abs_32o8er3uqp/croot/pillow_1721059447598/work\n",
    "pipreqs==0.5.0\n",
    "platformdirs @ file:///C:/b/abs_b6z_yqw_ii/croot/platformdirs_1692205479426/work\n",
    "plotly @ file:///C:/b/abs_9asyl7560v/croot/plotly_1718136949929/work\n",
    "plotly-express==0.4.1\n",
    "ply==3.11\n",
    "prometheus-client @ file:///C:/Windows/TEMP/abs_ab9nx8qb08/croots/recipe/prometheus_client_1659455104602/work\n",
    "prompt-toolkit @ file:///C:/b/abs_68uwr58ed1/croot/prompt-toolkit_1704404394082/work\n",
    "psutil @ file:///C:/Windows/Temp/abs_b2c2fd7f-9fd5-4756-95ea-8aed74d0039flsd9qufz/croots/recipe/psutil_1656431277748/work\n",
    "pure-eval @ file:///opt/conda/conda-bld/pure_eval_1646925070566/work\n",
    "pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\n",
    "Pygments @ file:///C:/b/abs_fay9dpq4n_/croot/pygments_1684279990574/work\n",
    "pyparsing @ file:///C:/b/abs_520r19rysg/croot/pyparsing_1725041656021/work\n",
    "PyQt5==5.15.10\n",
    "PyQt5-sip @ file:///C:/b/abs_c0pi2mimq3/croot/pyqt-split_1698769125270/work/pyqt_sip\n",
    "PySocks @ file:///C:/ci_310/pysocks_1642089375450/work\n",
    "python-dateutil @ file:///C:/b/abs_3au_koqnbs/croot/python-dateutil_1716495777160/work\n",
    "python-json-logger @ file:///C:/b/abs_cblnsm6puj/croot/python-json-logger_1683824130469/work\n",
    "pytz @ file:///C:/b/abs_6ap4tsz1ox/croot/pytz_1713974360290/work\n",
    "pywin32==305.1\n",
    "pywinpty @ file:///C:/b/abs_73vshmevwq/croot/pywinpty_1677609966356/work/target/wheels/pywinpty-2.0.10-cp310-none-win_amd64.whl\n",
    "PyYAML @ file:///C:/b/abs_782o3mbw7z/croot/pyyaml_1698096085010/work\n",
    "pyzmq @ file:///C:/b/abs_89aq69t0up/croot/pyzmq_1705605705281/work\n",
    "qtconsole @ file:///C:/b/abs_03f8rg9vl6/croot/qtconsole_1709231218069/work\n",
    "QtPy @ file:///C:/b/abs_derqu__3p8/croot/qtpy_1700144907661/work\n",
    "referencing @ file:///C:/b/abs_09f4hj6adf/croot/referencing_1699012097448/work\n",
    "requests @ file:///C:/b/abs_9frifg92q2/croot/requests_1721410901096/work\n",
    "rfc3339-validator @ file:///C:/b/abs_ddfmseb_vm/croot/rfc3339-validator_1683077054906/work\n",
    "rfc3986-validator @ file:///C:/b/abs_6e9azihr8o/croot/rfc3986-validator_1683059049737/work\n",
    "rpds-py @ file:///C:/b/abs_76j4g4la23/croot/rpds-py_1698947348047/work\n",
    "scipy @ file:///C:/bld/scipy-split_1724327194933/work/dist/scipy-1.14.1-cp310-cp310-win_amd64.whl#sha256=e6bdc831fca55b320340d9d65555e680654f474b6605e599cfd60b4c00f7d5d6\n",
    "selenium @ file:///home/conda/feedstock_root/build_artifacts/selenium_1696010260379/work\n",
    "Send2Trash @ file:///C:/b/abs_08dh49ew26/croot/send2trash_1699371173324/work\n",
    "sip @ file:///C:/b/abs_edevan3fce/croot/sip_1698675983372/work\n",
    "six @ file:///tmp/build/80754af9/six_1644875935023/work\n",
    "sniffio @ file:///C:/b/abs_3akdewudo_/croot/sniffio_1705431337396/work\n",
    "sortedcontainers @ file:///tmp/build/80754af9/sortedcontainers_1623949099177/work\n",
    "soupsieve @ file:///C:/b/abs_bbsvy9t4pl/croot/soupsieve_1696347611357/work\n",
    "stack-data @ file:///opt/conda/conda-bld/stack_data_1646927590127/work\n",
    "statsmodels @ file:///D:/bld/statsmodels_1715941409651/work\n",
    "tabulate==0.9.0\n",
    "tenacity @ file:///C:/b/abs_d2_havtscu/croot/tenacity_1721222514290/work\n",
    "terminado @ file:///C:/b/abs_25nakickad/croot/terminado_1671751845491/work\n",
    "tinycss2 @ file:///C:/b/abs_52w5vfuaax/croot/tinycss2_1668168823131/work\n",
    "tomli @ file:///C:/Windows/TEMP/abs_ac109f85-a7b3-4b4d-bcfd-52622eceddf0hy332ojo/croots/recipe/tomli_1657175513137/work\n",
    "tornado @ file:///C:/b/abs_7bua0304mj/croot/tornado_1718740122405/work\n",
    "tqdm==4.66.5\n",
    "traitlets @ file:///C:/b/abs_bfsnoxl4pq/croot/traitlets_1718227069245/work\n",
    "trio @ file:///C:/b/abs_3bsokxbl8q/croot/trio_1705518572139/work\n",
    "trio-websocket @ file:///home/conda/feedstock_root/build_artifacts/trio-websocket_1695816857197/work/dist\n",
    "typing_extensions @ file:///C:/b/abs_0as9mdbkfl/croot/typing_extensions_1715268906610/work\n",
    "tzdata @ file:///croot/python-tzdata_1690578112552/work\n",
    "unicodedata2 @ file:///C:/b/abs_b6apldlg7y/croot/unicodedata2_1713212998255/work\n",
    "urllib3 @ file:///C:/b/abs_aen1x8xlvc/croot/urllib3_1688592717643/work\n",
    "wcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work\n",
    "webencodings==0.5.1\n",
    "websocket-client @ file:///C:/b/abs_5dmnxxoci9/croot/websocket-client_1715878351319/work\n",
    "widgetsnbextension @ file:///C:/b/abs_a84ycxud7_/croot/widgetsnbextension_1709322945280/work\n",
    "win-inet-pton @ file:///C:/ci_310/win_inet_pton_1642658466512/work\n",
    "wsproto @ file:///home/conda/feedstock_root/build_artifacts/wsproto_1661356345548/work\n",
    "xlrd==2.0.1\n",
    "yarg==0.1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('./backups/', ['2022-10-16', '2023-10-06'], []),\n",
       " ('./backups/2022-10-16',\n",
       "  [],\n",
       "  ['avepettm_backup.xlsx',\n",
       "   'nets_end.xlsx',\n",
       "   'pe_and_dv.xlsx',\n",
       "   'profit_forecast.xlsx']),\n",
       " ('./backups/2023-10-06',\n",
       "  [],\n",
       "  ['avepettm_backup.xlsx',\n",
       "   'nets_end.xlsx',\n",
       "   'pe_and_dv.xlsx',\n",
       "   'profit_forecast.xlsx'])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "list(os.walk('./backups/')) # [0][1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firefox202304geckodriver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
